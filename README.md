# Metaverse music-triggered fashion
## Context
The metaverse promises to be one of the revolutionary technologies in the upcoming years, with more and more presence in our daily lives, offering immersive environments where individuals can work, socialise, and explore virtual realms. Despite not being a widely-adopted invention, there are some committed users who not only frequent these digital spaces but also integrate them into their daily routines, living part of their lives within its virtual confines and even utilising it for work. 

Among the inhabitants of the metaverse, musicians and performers, in particular, use this platform to showcase their talents and engage with audiences on a global scale.  In the realm of music, aesthetics play a crucial role in conveying the mood and atmosphere of a performance, and as the metaverse continues to evolve, artists have expressed a need to better integrate their appearance with their craft. 
To help them, we've looked into existing 'self-changing' clothes, such as colour-changing dresses or clothing pieces that light up. In the ‘real’ world it is, currently, virtually impossible to have an outfit drastically change, even quick-change performances relly on certain shapes of the clothing, and most existent technologies do not change the base outfit itself, just colour, light or in the most impressive cases shape of a specific part. This limitation however doesn’t exist in the virtual world. 

Thus, we have explored the idea of music-triggered clothing that changes depending on the music playing around them. The main plan is to develop this idea further and create a prototype of a Deep Learning model that, given a song, suggests an outfit or a selection of clothes tailored to the music's mood and tempo. In doing so, we aim not only to enhance the visual experience of performances but also to address broader social issues, such as the intersection of identity and individuality through clothing.
